{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Word Embeddings**\n",
    "\n",
    "**Word embeddings** in NLP are dense vector representations of words that capture their meanings based on context. Unlike traditional representations like Bag of Words or TF-IDF, which treat words as isolated units, word embeddings map words to vectors in a continuous space, where semantically similar words are closer to each other.\n",
    "\n",
    "Key characteristics of word embeddings:\n",
    "- They preserve **semantic relationships** between words (e.g., \"king\" and \"queen\" are close in the vector space, while \"king\" and \"apple\" are far apart).\n",
    "- They allow for capturing complex relationships, such as analogies (e.g., **\"king\" - \"man\" + \"woman\" = \"queen\"**).\n",
    "  \n",
    "Popular techniques for generating word embeddings include:\n",
    "- **Word2Vec**: Generates embeddings by training on word co-occurrence in large text corpora using methods like Skip-Gram or Continuous Bag of Words (CBOW).\n",
    "- **GloVe**: Produces embeddings by leveraging word co-occurrence statistics across the entire corpus.\n",
    "- **FastText**: Extends Word2Vec by considering subword information, improving performance on morphologically rich languages.\n",
    "\n",
    "Word embeddings are essential for tasks like machine translation, text classification, and sentiment analysis, as they help capture deeper meanings and relationships in language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=['she looks awesome',\n",
    "     'she looks awful',\n",
    "     'she looks amazing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processed=[]\n",
    "for i in doc:\n",
    "    doc_processed.append(gensim.utils.simple_preprocess(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['she', 'looks', 'awesome'],\n",
       " ['she', 'looks', 'awful'],\n",
       " ['she', 'looks', 'amazing']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v=gensim.models.Word2Vec(window=2,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.build_vocab(doc_processed,progress_per=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looks', 'she', 'amazing', 'awful', 'awesome']\n"
     ]
    }
   ],
   "source": [
    "print(w2v.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.train(doc_processed,total_examples=w2v.corpus_count,epochs=w2v.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('awesome', 0.17018885910511017),\n",
       " ('awful', -0.013514922931790352),\n",
       " ('she', -0.023671654984354973),\n",
       " ('looks', -0.05234673619270325)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0045030187"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.similarity('awesome','she')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
